{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v2 of Detectron2 Modification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrzhuzhe/Patrick/blob/main/v2_of_Detectron2_Modification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsePPpwZSmqt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6147f29d-3c9a-4bd7-9410-bc8e20602b84"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 5.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=7c56faeddd176e9a0d30851c90b7a55ca8a9671e77b16df6a67a36eca788c0b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
            "Collecting detectron2\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 606 kB/s \n",
            "\u001b[?25hCollecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.3)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20211023.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Collecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.62.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n",
            "Collecting regex>=2020.1.8\n",
            "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 50.0 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 81.4 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.24)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.42.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.1)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20211023-py3-none-any.whl size=60947 sha256=80067ddc4876856ec4e94e43019082d7a71f2473df9d96aa6b94840515959b60\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/98/fc/252d62cab6263c719120e06b28f3378af59b52ce7a20e81852\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=3048319e794fd030ae794646035128242332c5e3f49674918e1a95db17a2a81d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, regex, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6+cu111 fvcore-0.1.5.post20211023 hydra-core-1.1.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.3.2 regex-2021.11.10 typed-ast-1.5.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DcQW8jCzdFu"
      },
      "source": [
        "#!pip install timm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFeIFHgqMK1n"
      },
      "source": [
        "#import timm\n",
        "#from timm.models.efficientnet import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW_uxId-TwaO"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xfNmqoHLTvUm",
        "outputId": "8e25d583-9628-440d-97e9-0e12b0395228"
      },
      "source": [
        "# download, decompress the data\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n",
        "!unzip balloon_dataset.zip > /dev/null\n",
        "\n",
        "\n",
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
        "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
        "\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def get_balloon_dicts(img_dir):\n",
        "    json_file = os.path.join(img_dir, \"via_region_data.json\")\n",
        "    with open(json_file) as f:\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for idx, v in enumerate(imgs_anns.values()):\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(img_dir, v[\"filename\"])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "      \n",
        "        annos = v[\"regions\"]\n",
        "        objs = []\n",
        "        for _, anno in annos.items():\n",
        "            assert not anno[\"region_attributes\"]\n",
        "            anno = anno[\"shape_attributes\"]\n",
        "            px = anno[\"all_points_x\"]\n",
        "            py = anno[\"all_points_y\"]\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": 0,\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "for d in [\"train\", \"val\"]:\n",
        "    DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n",
        "    MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n",
        "balloon_metadata = MetadataCatalog.get(\"balloon_train\")\n",
        "\n",
        "dataset_dicts = get_balloon_dicts(\"balloon/train\")\n",
        "\"\"\"\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 09:45:56--  https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/107595270/737339e2-2b83-11e8-856a-188034eb3468?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211202%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211202T094556Z&X-Amz-Expires=300&X-Amz-Signature=5c3f372e6aeca959126633d89575ae34f917b24e89aadbcd605d6cd92b3f15ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=107595270&response-content-disposition=attachment%3B%20filename%3Dballoon_dataset.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-02 09:45:56--  https://github-releases.githubusercontent.com/107595270/737339e2-2b83-11e8-856a-188034eb3468?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211202%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211202T094556Z&X-Amz-Expires=300&X-Amz-Signature=5c3f372e6aeca959126633d89575ae34f917b24e89aadbcd605d6cd92b3f15ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=107595270&response-content-disposition=attachment%3B%20filename%3Dballoon_dataset.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.110.154, 185.199.109.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.110.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38741381 (37M) [application/octet-stream]\n",
            "Saving to: ‘balloon_dataset.zip’\n",
            "\n",
            "balloon_dataset.zip 100%[===================>]  36.95M  98.5MB/s    in 0.4s    \n",
            "\n",
            "2021-12-02 09:45:57 (98.5 MB/s) - ‘balloon_dataset.zip’ saved [38741381/38741381]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor d in random.sample(dataset_dicts, 3):\\n    img = cv2.imread(d[\"file_name\"])\\n    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=0.5)\\n    out = visualizer.draw_dataset_dict(d)\\n    cv2_imshow(out.get_image()[:, :, ::-1])\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFDQ09DDfWtV"
      },
      "source": [
        "# Dependences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_97Up6HIVyE"
      },
      "source": [
        "import math\n",
        "import fvcore.nn.weight_init as weight_init\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "from detectron2.modeling.backbone.build import BACKBONE_REGISTRY"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJoaXYQP7nId"
      },
      "source": [
        "from detectron2.modeling.backbone import Backbone\n",
        "\n",
        "from detectron2.layers import (\n",
        "    CNNBlockBase,\n",
        "    Conv2d,\n",
        "    DeformConv,\n",
        "    ModulatedDeformConv,\n",
        "    ShapeSpec,\n",
        "    get_norm,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdhwWRaAfLl-"
      },
      "source": [
        "# CFG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfKrQOCifNXV"
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"balloon_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 300   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDLl9zHRS78d"
      },
      "source": [
        "# CNN BACKBONE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dUPyPx0gHn8"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yDAocN32gFtg",
        "outputId": "841a48a3-d2c5-445d-ef05-946393cf2521"
      },
      "source": [
        "from detectron2.modeling.backbone.resnet import BasicBlock, BottleneckBlock, DeformBottleneckBlock, BasicStem\n",
        "\n",
        "class ResNet(Backbone):\n",
        "    \"\"\"\n",
        "    Implement :paper:`ResNet`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, stem, stages, num_classes=None, out_features=None, freeze_at=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            stem (nn.Module): a stem module\n",
        "            stages (list[list[CNNBlockBase]]): several (typically 4) stages,\n",
        "                each contains multiple :class:`CNNBlockBase`.\n",
        "            num_classes (None or int): if None, will not perform classification.\n",
        "                Otherwise, will create a linear layer.\n",
        "            out_features (list[str]): name of the layers whose outputs should\n",
        "                be returned in forward. Can be anything in \"stem\", \"linear\", or \"res2\" ...\n",
        "                If None, will return the output of the last layer.\n",
        "            freeze_at (int): The number of stages at the beginning to freeze.\n",
        "                see :meth:`freeze` for detailed explanation.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.stem = stem\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        current_stride = self.stem.stride\n",
        "        self._out_feature_strides = {\"stem\": current_stride}\n",
        "        self._out_feature_channels = {\"stem\": self.stem.out_channels}\n",
        "\n",
        "        self.stage_names, self.stages = [], []\n",
        "\n",
        "        if out_features is not None:\n",
        "            # Avoid keeping unused layers in this module. They consume extra memory\n",
        "            # and may cause allreduce to fail\n",
        "            num_stages = max(\n",
        "                [{\"res2\": 1, \"res3\": 2, \"res4\": 3, \"res5\": 4}.get(f, 0) for f in out_features]\n",
        "            )\n",
        "            stages = stages[:num_stages]\n",
        "        for i, blocks in enumerate(stages):\n",
        "            assert len(blocks) > 0, len(blocks)\n",
        "            for block in blocks:\n",
        "                assert isinstance(block, CNNBlockBase), block\n",
        "\n",
        "            name = \"res\" + str(i + 2)\n",
        "            stage = nn.Sequential(*blocks)\n",
        "\n",
        "            self.add_module(name, stage)\n",
        "            self.stage_names.append(name)\n",
        "            self.stages.append(stage)\n",
        "\n",
        "            self._out_feature_strides[name] = current_stride = int(\n",
        "                current_stride * np.prod([k.stride for k in blocks])\n",
        "            )\n",
        "            self._out_feature_channels[name] = curr_channels = blocks[-1].out_channels\n",
        "        self.stage_names = tuple(self.stage_names)  # Make it static for scripting\n",
        "        \n",
        "        #logger.info(\"_out_feature_strides\", self._out_feature_strides)\n",
        "\n",
        "        #logger.info(\"_out_feature_channels\", self._out_feature_channels)\n",
        "\n",
        "        if num_classes is not None:\n",
        "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "            self.linear = nn.Linear(curr_channels, num_classes)\n",
        "\n",
        "            # Sec 5.1 in \"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\":\n",
        "            # \"The 1000-way fully-connected layer is initialized by\n",
        "            # drawing weights from a zero-mean Gaussian with standard deviation of 0.01.\"\n",
        "            nn.init.normal_(self.linear.weight, std=0.01)\n",
        "            name = \"linear\"\n",
        "\n",
        "        if out_features is None:\n",
        "            out_features = [name]\n",
        "        self._out_features = out_features\n",
        "        assert len(self._out_features)\n",
        "        children = [x[0] for x in self.named_children()]\n",
        "        for out_feature in self._out_features:\n",
        "            assert out_feature in children, \"Available children: {}\".format(\", \".join(children))\n",
        "        self.freeze(freeze_at)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor of shape (N,C,H,W). H, W must be a multiple of ``self.size_divisibility``.\n",
        "\n",
        "        Returns:\n",
        "            dict[str->Tensor]: names and the corresponding features\n",
        "        \"\"\"\n",
        "        assert x.dim() == 4, f\"ResNet takes an input of shape (N, C, H, W). Got {x.shape} instead!\"\n",
        "        outputs = {}\n",
        "        x = self.stem(x)\n",
        "        if \"stem\" in self._out_features:\n",
        "            outputs[\"stem\"] = x\n",
        "        for name, stage in zip(self.stage_names, self.stages):\n",
        "            x = stage(x)\n",
        "            if name in self._out_features:\n",
        "                outputs[name] = x\n",
        "        if self.num_classes is not None:\n",
        "            x = self.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.linear(x)\n",
        "            if \"linear\" in self._out_features:\n",
        "                outputs[\"linear\"] = x\n",
        "        return outputs\n",
        "\n",
        "    def output_shape(self):\n",
        "        return {\n",
        "            name: ShapeSpec(\n",
        "                channels=self._out_feature_channels[name], stride=self._out_feature_strides[name]\n",
        "            )\n",
        "            for name in self._out_features\n",
        "        }\n",
        "\n",
        "    def freeze(self, freeze_at=0):\n",
        "        \"\"\"\n",
        "        Freeze the first several stages of the ResNet. Commonly used in\n",
        "        fine-tuning.\n",
        "\n",
        "        Layers that produce the same feature map spatial size are defined as one\n",
        "        \"stage\" by :paper:`FPN`.\n",
        "\n",
        "        Args:\n",
        "            freeze_at (int): number of stages to freeze.\n",
        "                `1` means freezing the stem. `2` means freezing the stem and\n",
        "                one residual stage, etc.\n",
        "\n",
        "        Returns:\n",
        "            nn.Module: this ResNet itself\n",
        "        \"\"\"\n",
        "        if freeze_at >= 1:\n",
        "            self.stem.freeze()\n",
        "        for idx, stage in enumerate(self.stages, start=2):\n",
        "            if freeze_at >= idx:\n",
        "                for block in stage.children():\n",
        "                    block.freeze()\n",
        "        return self\n",
        "\n",
        "    @staticmethod\n",
        "    def make_stage(block_class, num_blocks, *, in_channels, out_channels, **kwargs):\n",
        "        \"\"\"\n",
        "        Create a list of blocks of the same type that forms one ResNet stage.\n",
        "\n",
        "        Args:\n",
        "            block_class (type): a subclass of CNNBlockBase that's used to create all blocks in this\n",
        "                stage. A module of this type must not change spatial resolution of inputs unless its\n",
        "                stride != 1.\n",
        "            num_blocks (int): number of blocks in this stage\n",
        "            in_channels (int): input channels of the entire stage.\n",
        "            out_channels (int): output channels of **every block** in the stage.\n",
        "            kwargs: other arguments passed to the constructor of\n",
        "                `block_class`. If the argument name is \"xx_per_block\", the\n",
        "                argument is a list of values to be passed to each block in the\n",
        "                stage. Otherwise, the same argument is passed to every block\n",
        "                in the stage.\n",
        "\n",
        "        Returns:\n",
        "            list[CNNBlockBase]: a list of block module.\n",
        "\n",
        "        Examples:\n",
        "        ::\n",
        "            stage = ResNet.make_stage(\n",
        "                BottleneckBlock, 3, in_channels=16, out_channels=64,\n",
        "                bottleneck_channels=16, num_groups=1,\n",
        "                stride_per_block=[2, 1, 1],\n",
        "                dilations_per_block=[1, 1, 2]\n",
        "            )\n",
        "\n",
        "        Usually, layers that produce the same feature map spatial size are defined as one\n",
        "        \"stage\" (in :paper:`FPN`). Under such definition, ``stride_per_block[1:]`` should\n",
        "        all be 1.\n",
        "        \"\"\"\n",
        "        blocks = []\n",
        "        for i in range(num_blocks):\n",
        "            curr_kwargs = {}\n",
        "            for k, v in kwargs.items():\n",
        "                if k.endswith(\"_per_block\"):\n",
        "                    assert len(v) == num_blocks, (\n",
        "                        f\"Argument '{k}' of make_stage should have the \"\n",
        "                        f\"same length as num_blocks={num_blocks}.\"\n",
        "                    )\n",
        "                    newk = k[: -len(\"_per_block\")]\n",
        "                    assert newk not in kwargs, f\"Cannot call make_stage with both {k} and {newk}!\"\n",
        "                    curr_kwargs[newk] = v[i]\n",
        "                else:\n",
        "                    curr_kwargs[k] = v\n",
        "\n",
        "            blocks.append(\n",
        "                block_class(in_channels=in_channels, out_channels=out_channels, **curr_kwargs)\n",
        "            )\n",
        "            in_channels = out_channels\n",
        "        return blocks\n",
        "\n",
        "    @staticmethod\n",
        "    def make_default_stages(depth, block_class=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Created list of ResNet stages from pre-defined depth (one of 18, 34, 50, 101, 152).\n",
        "        If it doesn't create the ResNet variant you need, please use :meth:`make_stage`\n",
        "        instead for fine-grained customization.\n",
        "\n",
        "        Args:\n",
        "            depth (int): depth of ResNet\n",
        "            block_class (type): the CNN block class. Has to accept\n",
        "                `bottleneck_channels` argument for depth > 50.\n",
        "                By default it is BasicBlock or BottleneckBlock, based on the\n",
        "                depth.\n",
        "            kwargs:\n",
        "                other arguments to pass to `make_stage`. Should not contain\n",
        "                stride and channels, as they are predefined for each depth.\n",
        "\n",
        "        Returns:\n",
        "            list[list[CNNBlockBase]]: modules in all stages; see arguments of\n",
        "                :class:`ResNet.__init__`.\n",
        "        \"\"\"\n",
        "        num_blocks_per_stage = {\n",
        "            18: [2, 2, 2, 2],\n",
        "            34: [3, 4, 6, 3],\n",
        "            50: [3, 4, 6, 3],\n",
        "            101: [3, 4, 23, 3],\n",
        "            152: [3, 8, 36, 3],\n",
        "        }[depth]\n",
        "        if block_class is None:\n",
        "            block_class = BasicBlock if depth < 50 else BottleneckBlock\n",
        "        if depth < 50:\n",
        "            in_channels = [64, 64, 128, 256]\n",
        "            out_channels = [64, 128, 256, 512]\n",
        "        else:\n",
        "            in_channels = [64, 256, 512, 1024]\n",
        "            out_channels = [256, 512, 1024, 2048]\n",
        "        ret = []\n",
        "        for (n, s, i, o) in zip(num_blocks_per_stage, [1, 2, 2, 2], in_channels, out_channels):\n",
        "            if depth >= 50:\n",
        "                kwargs[\"bottleneck_channels\"] = o // 4\n",
        "            ret.append(\n",
        "                ResNet.make_stage(\n",
        "                    block_class=block_class,\n",
        "                    num_blocks=n,\n",
        "                    stride_per_block=[s] + [1] * (n - 1),\n",
        "                    in_channels=i,\n",
        "                    out_channels=o,\n",
        "                    **kwargs,\n",
        "                )\n",
        "            )\n",
        "        return ret\n",
        "\n",
        "\n",
        "ResNetBlockBase = CNNBlockBase\n",
        "\"\"\"\n",
        "Alias for backward compatibiltiy.\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nAlias for backward compatibiltiy.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF7ttlAVgK_w"
      },
      "source": [
        "## Stages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keDgsNxvt8Gv"
      },
      "source": [
        "def make_stage(*args, **kwargs):\n",
        "    \"\"\"\n",
        "    Deprecated alias for backward compatibiltiy.\n",
        "    \"\"\"\n",
        "    return ResNet.make_stage(*args, **kwargs)\n",
        "\n",
        "del BACKBONE_REGISTRY._obj_map[\"build_resnet_backbone\"] \n",
        "@BACKBONE_REGISTRY.register()\n",
        "def build_resnet_backbone(cfg, input_shape):\n",
        "    \"\"\"\n",
        "    Create a ResNet instance from config.\n",
        "\n",
        "    Returns:\n",
        "        ResNet: a :class:`ResNet` instance.\n",
        "    \"\"\"\n",
        "    # need registration of new blocks/stems?\n",
        "    norm = cfg.MODEL.RESNETS.NORM\n",
        "    stem = BasicStem(\n",
        "        in_channels=input_shape.channels,\n",
        "        out_channels=cfg.MODEL.RESNETS.STEM_OUT_CHANNELS,\n",
        "        norm=norm,\n",
        "    )\n",
        "\n",
        "    # fmt: off\n",
        "    freeze_at           = cfg.MODEL.BACKBONE.FREEZE_AT\n",
        "    out_features        = cfg.MODEL.RESNETS.OUT_FEATURES\n",
        "    depth               = cfg.MODEL.RESNETS.DEPTH\n",
        "    num_groups          = cfg.MODEL.RESNETS.NUM_GROUPS\n",
        "    width_per_group     = cfg.MODEL.RESNETS.WIDTH_PER_GROUP\n",
        "    bottleneck_channels = num_groups * width_per_group\n",
        "    in_channels         = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS\n",
        "    out_channels        = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS\n",
        "    stride_in_1x1       = cfg.MODEL.RESNETS.STRIDE_IN_1X1\n",
        "    res5_dilation       = cfg.MODEL.RESNETS.RES5_DILATION\n",
        "    deform_on_per_stage = cfg.MODEL.RESNETS.DEFORM_ON_PER_STAGE\n",
        "    deform_modulated    = cfg.MODEL.RESNETS.DEFORM_MODULATED\n",
        "    deform_num_groups   = cfg.MODEL.RESNETS.DEFORM_NUM_GROUPS\n",
        "    # fmt: on\n",
        "    assert res5_dilation in {1, 2}, \"res5_dilation cannot be {}.\".format(res5_dilation)\n",
        "\n",
        "    num_blocks_per_stage = {\n",
        "        18: [2, 2, 2, 2],\n",
        "        34: [3, 4, 6, 3],\n",
        "        50: [3, 4, 6, 3],\n",
        "        101: [3, 4, 23, 3],\n",
        "        152: [3, 8, 36, 3],\n",
        "    }[depth]\n",
        "\n",
        "    if depth in [18, 34]:\n",
        "        assert out_channels == 64, \"Must set MODEL.RESNETS.RES2_OUT_CHANNELS = 64 for R18/R34\"\n",
        "        assert not any(\n",
        "            deform_on_per_stage\n",
        "        ), \"MODEL.RESNETS.DEFORM_ON_PER_STAGE unsupported for R18/R34\"\n",
        "        assert res5_dilation == 1, \"Must set MODEL.RESNETS.RES5_DILATION = 1 for R18/R34\"\n",
        "        assert num_groups == 1, \"Must set MODEL.RESNETS.NUM_GROUPS = 1 for R18/R34\"\n",
        "\n",
        "    stages = []\n",
        "\n",
        "    for idx, stage_idx in enumerate(range(2, 6)):\n",
        "        # res5_dilation is used this way as a convention in R-FCN & Deformable Conv paper\n",
        "        dilation = res5_dilation if stage_idx == 5 else 1\n",
        "        first_stride = 1 if idx == 0 or (stage_idx == 5 and dilation == 2) else 2\n",
        "        stage_kargs = {\n",
        "            \"num_blocks\": num_blocks_per_stage[idx],\n",
        "            \"stride_per_block\": [first_stride] + [1] * (num_blocks_per_stage[idx] - 1),\n",
        "            \"in_channels\": in_channels,\n",
        "            \"out_channels\": out_channels,\n",
        "            \"norm\": norm,\n",
        "        }\n",
        "        # Use BasicBlock for R18 and R34.\n",
        "        if depth in [18, 34]:\n",
        "            stage_kargs[\"block_class\"] = BasicBlock\n",
        "        else:\n",
        "            stage_kargs[\"bottleneck_channels\"] = bottleneck_channels\n",
        "            stage_kargs[\"stride_in_1x1\"] = stride_in_1x1\n",
        "            stage_kargs[\"dilation\"] = dilation\n",
        "            stage_kargs[\"num_groups\"] = num_groups\n",
        "            if deform_on_per_stage[idx]:\n",
        "                stage_kargs[\"block_class\"] = DeformBottleneckBlock\n",
        "                stage_kargs[\"deform_modulated\"] = deform_modulated\n",
        "                stage_kargs[\"deform_num_groups\"] = deform_num_groups\n",
        "            else:\n",
        "                stage_kargs[\"block_class\"] = BottleneckBlock\n",
        "        blocks = ResNet.make_stage(**stage_kargs)\n",
        "        in_channels = out_channels\n",
        "        out_channels *= 2\n",
        "        bottleneck_channels *= 2\n",
        "        stages.append(blocks)\n",
        "    #print(\"stages\", stages)\n",
        "    return ResNet(stem, stages, out_features=out_features, freeze_at=freeze_at)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANN2vpDEgNCV"
      },
      "source": [
        "## Check Backbone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY1RrkhUeXid",
        "outputId": "542d3e52-a8a3-41cb-f47e-a32d7d023fbf"
      },
      "source": [
        "input_shape = ShapeSpec(channels=3, height=None, width=None, stride=None)\n",
        "bottom_up = build_resnet_backbone(cfg, input_shape)\n",
        "print(\"_out_feature_channels\", bottom_up._out_feature_channels)\n",
        "print(\"_out_feature_strides\", bottom_up._out_feature_strides)\n",
        "print(\"output_shape\", bottom_up.output_shape())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_out_feature_channels {'stem': 64, 'res2': 256, 'res3': 512, 'res4': 1024, 'res5': 2048}\n",
            "_out_feature_strides {'stem': 4, 'res2': 4, 'res3': 8, 'res4': 16, 'res5': 32}\n",
            "output_shape {'res2': ShapeSpec(channels=256, height=None, width=None, stride=4), 'res3': ShapeSpec(channels=512, height=None, width=None, stride=8), 'res4': ShapeSpec(channels=1024, height=None, width=None, stride=16), 'res5': ShapeSpec(channels=2048, height=None, width=None, stride=32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4MJqVG6S-wt"
      },
      "source": [
        "# FPN BACKBONE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-9l-6y01ffe"
      },
      "source": [
        "from detectron2.modeling.backbone.fpn import _assert_strides_are_log2_contiguous, LastLevelMaxPool\n",
        "\n",
        "class FPN(Backbone):\n",
        "    \"\"\"\n",
        "    This module implements :paper:`FPN`.\n",
        "    It creates pyramid features built on top of some input feature maps.\n",
        "    \"\"\"\n",
        "\n",
        "    _fuse_type: torch.jit.Final[str]\n",
        "\n",
        "    def __init__(\n",
        "        self, bottom_up, in_features, out_channels, norm=\"\", top_block=None, fuse_type=\"sum\"\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            bottom_up (Backbone): module representing the bottom up subnetwork.\n",
        "                Must be a subclass of :class:`Backbone`. The multi-scale feature\n",
        "                maps generated by the bottom up network, and listed in `in_features`,\n",
        "                are used to generate FPN levels.\n",
        "            in_features (list[str]): names of the input feature maps coming\n",
        "                from the backbone to which FPN is attached. For example, if the\n",
        "                backbone produces [\"res2\", \"res3\", \"res4\"], any *contiguous* sublist\n",
        "                of these may be used; order must be from high to low resolution.\n",
        "            out_channels (int): number of channels in the output feature maps.\n",
        "            norm (str): the normalization to use.\n",
        "            top_block (nn.Module or None): if provided, an extra operation will\n",
        "                be performed on the output of the last (smallest resolution)\n",
        "                FPN output, and the result will extend the result list. The top_block\n",
        "                further downsamples the feature map. It must have an attribute\n",
        "                \"num_levels\", meaning the number of extra FPN levels added by\n",
        "                this block, and \"in_feature\", which is a string representing\n",
        "                its input feature (e.g., p5).\n",
        "            fuse_type (str): types for fusing the top down features and the lateral\n",
        "                ones. It can be \"sum\" (default), which sums up element-wise; or \"avg\",\n",
        "                which takes the element-wise mean of the two.\n",
        "        \"\"\"\n",
        "        super(FPN, self).__init__()\n",
        "        assert isinstance(bottom_up, Backbone)\n",
        "        assert in_features, in_features\n",
        "\n",
        "        # Feature map strides and channels from the bottom up network (e.g. ResNet)\n",
        "        input_shapes = bottom_up.output_shape()\n",
        "        strides = [input_shapes[f].stride for f in in_features]\n",
        "        in_channels_per_feature = [input_shapes[f].channels for f in in_features]\n",
        "\n",
        "        _assert_strides_are_log2_contiguous(strides)\n",
        "        lateral_convs = []\n",
        "        output_convs = []\n",
        "\n",
        "        use_bias = norm == \"\"\n",
        "        for idx, in_channels in enumerate(in_channels_per_feature):\n",
        "            lateral_norm = get_norm(norm, out_channels)\n",
        "            output_norm = get_norm(norm, out_channels)\n",
        "\n",
        "            lateral_conv = Conv2d(\n",
        "                in_channels, out_channels, kernel_size=1, bias=use_bias, norm=lateral_norm\n",
        "            )\n",
        "            output_conv = Conv2d(\n",
        "                out_channels,\n",
        "                out_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                bias=use_bias,\n",
        "                norm=output_norm,\n",
        "            )\n",
        "            weight_init.c2_xavier_fill(lateral_conv)\n",
        "            weight_init.c2_xavier_fill(output_conv)\n",
        "            stage = int(math.log2(strides[idx]))\n",
        "            self.add_module(\"fpn_lateral{}\".format(stage), lateral_conv)\n",
        "            self.add_module(\"fpn_output{}\".format(stage), output_conv)\n",
        "\n",
        "            lateral_convs.append(lateral_conv)\n",
        "            output_convs.append(output_conv)\n",
        "        # Place convs into top-down order (from low to high resolution)\n",
        "        # to make the top-down computation in forward clearer.\n",
        "        self.lateral_convs = lateral_convs[::-1]\n",
        "        self.output_convs = output_convs[::-1]\n",
        "        self.top_block = top_block\n",
        "        self.in_features = tuple(in_features)\n",
        "        self.bottom_up = bottom_up\n",
        "        # Return feature names are \"p<stage>\", like [\"p2\", \"p3\", ..., \"p6\"]\n",
        "        self._out_feature_strides = {\"p{}\".format(int(math.log2(s))): s for s in strides}\n",
        "        # top block output feature maps.\n",
        "        if self.top_block is not None:\n",
        "            for s in range(stage, stage + self.top_block.num_levels):\n",
        "                self._out_feature_strides[\"p{}\".format(s + 1)] = 2 ** (s + 1)\n",
        "\n",
        "        self._out_features = list(self._out_feature_strides.keys())\n",
        "        self._out_feature_channels = {k: out_channels for k in self._out_features}\n",
        "        self._size_divisibility = strides[-1]\n",
        "        assert fuse_type in {\"avg\", \"sum\"}\n",
        "        self._fuse_type = fuse_type\n",
        "\n",
        "    @property\n",
        "    def size_divisibility(self):\n",
        "        return self._size_divisibility\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input (dict[str->Tensor]): mapping feature map name (e.g., \"res5\") to\n",
        "                feature map tensor for each feature level in high to low resolution order.\n",
        "\n",
        "        Returns:\n",
        "            dict[str->Tensor]:\n",
        "                mapping from feature map name to FPN feature map tensor\n",
        "                in high to low resolution order. Returned feature names follow the FPN\n",
        "                paper convention: \"p<stage>\", where stage has stride = 2 ** stage e.g.,\n",
        "                [\"p2\", \"p3\", ..., \"p6\"].\n",
        "        \"\"\"\n",
        "        bottom_up_features = self.bottom_up(x)\n",
        "        results = []\n",
        "        prev_features = self.lateral_convs[0](bottom_up_features[self.in_features[-1]])\n",
        "        results.append(self.output_convs[0](prev_features))\n",
        "\n",
        "        # Reverse feature maps into top-down order (from low to high resolution)\n",
        "        for idx, (lateral_conv, output_conv) in enumerate(\n",
        "            zip(self.lateral_convs, self.output_convs)\n",
        "        ):\n",
        "            # Slicing of ModuleList is not supported https://github.com/pytorch/pytorch/issues/47336\n",
        "            # Therefore we loop over all modules but skip the first one\n",
        "            if idx > 0:\n",
        "                features = self.in_features[-idx - 1]\n",
        "                features = bottom_up_features[features]\n",
        "                top_down_features = F.interpolate(prev_features, scale_factor=2.0, mode=\"nearest\")\n",
        "                lateral_features = lateral_conv(features)\n",
        "                prev_features = lateral_features + top_down_features\n",
        "                if self._fuse_type == \"avg\":\n",
        "                    prev_features /= 2\n",
        "                results.insert(0, output_conv(prev_features))\n",
        "\n",
        "        if self.top_block is not None:\n",
        "            if self.top_block.in_feature in bottom_up_features:\n",
        "                top_block_in_feature = bottom_up_features[self.top_block.in_feature]\n",
        "            else:\n",
        "                top_block_in_feature = results[self._out_features.index(self.top_block.in_feature)]\n",
        "            results.extend(self.top_block(top_block_in_feature))\n",
        "        assert len(self._out_features) == len(results)\n",
        "        return {f: res for f, res in zip(self._out_features, results)}\n",
        "\n",
        "    def output_shape(self):\n",
        "        return {\n",
        "            name: ShapeSpec(\n",
        "                channels=self._out_feature_channels[name], stride=self._out_feature_strides[name]\n",
        "            )\n",
        "            for name in self._out_features\n",
        "        }\n",
        "\n",
        "del BACKBONE_REGISTRY._obj_map[\"build_resnet_fpn_backbone\"] \n",
        "@BACKBONE_REGISTRY.register()\n",
        "def build_resnet_fpn_backbone(cfg, input_shape: ShapeSpec):\n",
        "\n",
        "    print(\"456456456\")\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        cfg: a detectron2 CfgNode\n",
        "\n",
        "    Returns:\n",
        "        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n",
        "    \"\"\"\n",
        "    bottom_up = build_resnet_backbone(cfg, input_shape)\n",
        "    in_features = cfg.MODEL.FPN.IN_FEATURES\n",
        "    out_channels = cfg.MODEL.FPN.OUT_CHANNELS\n",
        "    backbone = FPN(\n",
        "        bottom_up=bottom_up,\n",
        "        in_features=in_features,\n",
        "        out_channels=out_channels,\n",
        "        norm=cfg.MODEL.FPN.NORM,\n",
        "        top_block=LastLevelMaxPool(),\n",
        "        fuse_type=cfg.MODEL.FPN.FUSE_TYPE,\n",
        "    )\n",
        "    return backbone"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNiGwV9xwCV6"
      },
      "source": [
        "# Cutomize Default trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU4sRdMIV6ZR"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "import re\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    resnet_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        if re.search(\"backbone.bottom_up\", name):\n",
        "          resnet_params += param\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    print(f\"Resnet Params: {resnet_params}\")\n",
        "    return total_params"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hy5xhmVwB_7"
      },
      "source": [
        "from detectron2.engine.defaults import create_ddp_model, default_writers\n",
        "from detectron2.engine import hooks\n",
        "\n",
        "from detectron2.data import (\n",
        "    build_detection_test_loader,\n",
        "    build_detection_train_loader,\n",
        ")\n",
        "\n",
        "from detectron2.engine.train_loop import AMPTrainer, SimpleTrainer, TrainerBase\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
        "\n",
        "\n",
        "from detectron2.evaluation import (\n",
        "    DatasetEvaluator,\n",
        "    inference_on_dataset,\n",
        "    print_csv_format,\n",
        "    verify_results,\n",
        ")\n",
        "\n",
        "import weakref\n",
        "import logging\n",
        "from detectron2.utils import comm\n",
        "from collections import OrderedDict\n",
        "\n",
        "class CustomizeTrainer(TrainerBase):\n",
        "    \"\"\"\n",
        "    A trainer with default training logic. It does the following:\n",
        "\n",
        "    1. Create a :class:`SimpleTrainer` using model, optimizer, dataloader\n",
        "       defined by the given config. Create a LR scheduler defined by the config.\n",
        "    2. Load the last checkpoint or `cfg.MODEL.WEIGHTS`, if exists, when\n",
        "       `resume_or_load` is called.\n",
        "    3. Register a few common hooks defined by the config.\n",
        "\n",
        "    It is created to simplify the **standard model training workflow** and reduce code boilerplate\n",
        "    for users who only need the standard training workflow, with standard features.\n",
        "    It means this class makes *many assumptions* about your training logic that\n",
        "    may easily become invalid in a new research. In fact, any assumptions beyond those made in the\n",
        "    :class:`SimpleTrainer` are too much for research.\n",
        "\n",
        "    The code of this class has been annotated about restrictive assumptions it makes.\n",
        "    When they do not work for you, you're encouraged to:\n",
        "\n",
        "    1. Overwrite methods of this class, OR:\n",
        "    2. Use :class:`SimpleTrainer`, which only does minimal SGD training and\n",
        "       nothing else. You can then add your own hooks if needed. OR:\n",
        "    3. Write your own training loop similar to `tools/plain_train_net.py`.\n",
        "\n",
        "    See the :doc:`/tutorials/training` tutorials for more details.\n",
        "\n",
        "    Note that the behavior of this class, like other functions/classes in\n",
        "    this file, is not stable, since it is meant to represent the \"common default behavior\".\n",
        "    It is only guaranteed to work well with the standard models and training workflow in detectron2.\n",
        "    To obtain more stable behavior, write your own training logic with other public APIs.\n",
        "\n",
        "    Examples:\n",
        "    ::\n",
        "        trainer = DefaultTrainer(cfg)\n",
        "        trainer.resume_or_load()  # load last checkpoint or MODEL.WEIGHTS\n",
        "        trainer.train()\n",
        "\n",
        "    Attributes:\n",
        "        scheduler:\n",
        "        checkpointer (DetectionCheckpointer):\n",
        "        cfg (CfgNode):\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            cfg (CfgNode):\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        logger = logging.getLogger(\"detectron2\")\n",
        "        if not logger.isEnabledFor(logging.INFO):  # setup_logger is not called for d2\n",
        "            setup_logger()\n",
        "        cfg = self.auto_scale_workers(cfg, comm.get_world_size())\n",
        "\n",
        "        # Assume these objects must be constructed in this order.\n",
        "        model = self.build_model(cfg)\n",
        "        optimizer = self.build_optimizer(cfg, model)\n",
        "        data_loader = self.build_train_loader(cfg)\n",
        "\n",
        "        model = create_ddp_model(model, broadcast_buffers=False)\n",
        "\n",
        "        #pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "        #print(\"parameters\", sum(dict((p.data_ptr(), p.numel()) for p in model.parameters()).values()))\n",
        "        \n",
        "        #print(\"pytorch_total_params\", pytorch_total_params)\n",
        "        count_parameters(model)\n",
        "            \n",
        "        self._trainer = (AMPTrainer if cfg.SOLVER.AMP.ENABLED else SimpleTrainer)(\n",
        "            model, data_loader, optimizer\n",
        "        )\n",
        "\n",
        "        self.scheduler = self.build_lr_scheduler(cfg, optimizer)\n",
        "        self.checkpointer = DetectionCheckpointer(\n",
        "            # Assume you want to save checkpoints together with logs/statistics\n",
        "            model,\n",
        "            cfg.OUTPUT_DIR,\n",
        "            trainer=weakref.proxy(self),\n",
        "        )\n",
        "        self.start_iter = 0\n",
        "        self.max_iter = cfg.SOLVER.MAX_ITER\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.register_hooks(self.build_hooks())\n",
        "\n",
        "    def resume_or_load(self, resume=True):\n",
        "        \"\"\"\n",
        "        If `resume==True` and `cfg.OUTPUT_DIR` contains the last checkpoint (defined by\n",
        "        a `last_checkpoint` file), resume from the file. Resuming means loading all\n",
        "        available states (eg. optimizer and scheduler) and update iteration counter\n",
        "        from the checkpoint. ``cfg.MODEL.WEIGHTS`` will not be used.\n",
        "\n",
        "        Otherwise, this is considered as an independent training. The method will load model\n",
        "        weights from the file `cfg.MODEL.WEIGHTS` (but will not load other states) and start\n",
        "        from iteration 0.\n",
        "\n",
        "        Args:\n",
        "            resume (bool): whether to do resume or not\n",
        "        \"\"\"\n",
        "        self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)\n",
        "        if resume and self.checkpointer.has_checkpoint():\n",
        "            # The checkpoint stores the training iteration that just finished, thus we start\n",
        "            # at the next iteration\n",
        "            self.start_iter = self.iter + 1\n",
        "\n",
        "    def build_hooks(self):\n",
        "        \"\"\"\n",
        "        Build a list of default hooks, including timing, evaluation,\n",
        "        checkpointing, lr scheduling, precise BN, writing events.\n",
        "\n",
        "        Returns:\n",
        "            list[HookBase]:\n",
        "        \"\"\"\n",
        "        cfg = self.cfg.clone()\n",
        "        cfg.defrost()\n",
        "        cfg.DATALOADER.NUM_WORKERS = 0  # save some memory and time for PreciseBN\n",
        "\n",
        "        ret = [\n",
        "            hooks.IterationTimer(),\n",
        "            hooks.LRScheduler(),\n",
        "            hooks.PreciseBN(\n",
        "                # Run at the same freq as (but before) evaluation.\n",
        "                cfg.TEST.EVAL_PERIOD,\n",
        "                self.model,\n",
        "                # Build a new data loader to not affect training\n",
        "                self.build_train_loader(cfg),\n",
        "                cfg.TEST.PRECISE_BN.NUM_ITER,\n",
        "            )\n",
        "            if cfg.TEST.PRECISE_BN.ENABLED and get_bn_modules(self.model)\n",
        "            else None,\n",
        "        ]\n",
        "\n",
        "        # Do PreciseBN before checkpointer, because it updates the model and need to\n",
        "        # be saved by checkpointer.\n",
        "        # This is not always the best: if checkpointing has a different frequency,\n",
        "        # some checkpoints may have more precise statistics than others.\n",
        "        if comm.is_main_process():\n",
        "            ret.append(hooks.PeriodicCheckpointer(self.checkpointer, cfg.SOLVER.CHECKPOINT_PERIOD))\n",
        "\n",
        "        def test_and_save_results():\n",
        "            self._last_eval_results = self.test(self.cfg, self.model)\n",
        "            return self._last_eval_results\n",
        "\n",
        "        # Do evaluation after checkpointer, because then if it fails,\n",
        "        # we can use the saved checkpoint to debug.\n",
        "        ret.append(hooks.EvalHook(cfg.TEST.EVAL_PERIOD, test_and_save_results))\n",
        "\n",
        "        if comm.is_main_process():\n",
        "            # Here the default print/log frequency of each writer is used.\n",
        "            # run writers in the end, so that evaluation metrics are written\n",
        "            ret.append(hooks.PeriodicWriter(self.build_writers(), period=20))\n",
        "        return ret\n",
        "\n",
        "    def build_writers(self):\n",
        "        \"\"\"\n",
        "        Build a list of writers to be used using :func:`default_writers()`.\n",
        "        If you'd like a different list of writers, you can overwrite it in\n",
        "        your trainer.\n",
        "\n",
        "        Returns:\n",
        "            list[EventWriter]: a list of :class:`EventWriter` objects.\n",
        "        \"\"\"\n",
        "        return default_writers(self.cfg.OUTPUT_DIR, self.max_iter)\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Run training.\n",
        "\n",
        "        Returns:\n",
        "            OrderedDict of results, if evaluation is enabled. Otherwise None.\n",
        "        \"\"\"\n",
        "        super().train(self.start_iter, self.max_iter)\n",
        "        if len(self.cfg.TEST.EXPECTED_RESULTS) and comm.is_main_process():\n",
        "            assert hasattr(\n",
        "                self, \"_last_eval_results\"\n",
        "            ), \"No evaluation results obtained during training!\"\n",
        "            verify_results(self.cfg, self._last_eval_results)\n",
        "            return self._last_eval_results\n",
        "\n",
        "    def run_step(self):\n",
        "        self._trainer.iter = self.iter\n",
        "        self._trainer.run_step()\n",
        "\n",
        "    def state_dict(self):\n",
        "        ret = super().state_dict()\n",
        "        ret[\"_trainer\"] = self._trainer.state_dict()\n",
        "        return ret\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        super().load_state_dict(state_dict)\n",
        "        self._trainer.load_state_dict(state_dict[\"_trainer\"])\n",
        "\n",
        "    @classmethod\n",
        "    def build_model(cls, cfg):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            torch.nn.Module:\n",
        "\n",
        "        It now calls :func:`detectron2.modeling.build_model`.\n",
        "        Overwrite it if you'd like a different model.\n",
        "        \"\"\"\n",
        "        model = build_model(cfg)\n",
        "        print(\"Model\", model)\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info(\"Model:\\n{}\".format(model))\n",
        "        return model\n",
        "\n",
        "    @classmethod\n",
        "    def build_optimizer(cls, cfg, model):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            torch.optim.Optimizer:\n",
        "\n",
        "        It now calls :func:`detectron2.solver.build_optimizer`.\n",
        "        Overwrite it if you'd like a different optimizer.\n",
        "        \"\"\"\n",
        "        return build_optimizer(cfg, model)\n",
        "\n",
        "    @classmethod\n",
        "    def build_lr_scheduler(cls, cfg, optimizer):\n",
        "        \"\"\"\n",
        "        It now calls :func:`detectron2.solver.build_lr_scheduler`.\n",
        "        Overwrite it if you'd like a different scheduler.\n",
        "        \"\"\"\n",
        "        return build_lr_scheduler(cfg, optimizer)\n",
        "\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            iterable\n",
        "\n",
        "        It now calls :func:`detectron2.data.build_detection_train_loader`.\n",
        "        Overwrite it if you'd like a different data loader.\n",
        "        \"\"\"\n",
        "        return build_detection_train_loader(cfg)\n",
        "\n",
        "    @classmethod\n",
        "    def build_test_loader(cls, cfg, dataset_name):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            iterable\n",
        "\n",
        "        It now calls :func:`detectron2.data.build_detection_test_loader`.\n",
        "        Overwrite it if you'd like a different data loader.\n",
        "        \"\"\"\n",
        "        return build_detection_test_loader(cfg, dataset_name)\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            DatasetEvaluator or None\n",
        "\n",
        "        It is not implemented by default.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\n",
        "            \"\"\"\n",
        "If you want DefaultTrainer to automatically run evaluation,\n",
        "please implement `build_evaluator()` in subclasses (see train_net.py for example).\n",
        "Alternatively, you can call evaluation functions yourself (see Colab balloon tutorial for example).\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def test(cls, cfg, model, evaluators=None):\n",
        "        \"\"\"\n",
        "        Evaluate the given model. The given model is expected to already contain\n",
        "        weights to evaluate.\n",
        "\n",
        "        Args:\n",
        "            cfg (CfgNode):\n",
        "            model (nn.Module):\n",
        "            evaluators (list[DatasetEvaluator] or None): if None, will call\n",
        "                :meth:`build_evaluator`. Otherwise, must have the same length as\n",
        "                ``cfg.DATASETS.TEST``.\n",
        "\n",
        "        Returns:\n",
        "            dict: a dict of result metrics\n",
        "        \"\"\"\n",
        "        logger = logging.getLogger(__name__)\n",
        "        if isinstance(evaluators, DatasetEvaluator):\n",
        "            evaluators = [evaluators]\n",
        "        if evaluators is not None:\n",
        "            assert len(cfg.DATASETS.TEST) == len(evaluators), \"{} != {}\".format(\n",
        "                len(cfg.DATASETS.TEST), len(evaluators)\n",
        "            )\n",
        "\n",
        "        results = OrderedDict()\n",
        "        for idx, dataset_name in enumerate(cfg.DATASETS.TEST):\n",
        "            data_loader = cls.build_test_loader(cfg, dataset_name)\n",
        "            # When evaluators are passed in as arguments,\n",
        "            # implicitly assume that evaluators can be created before data_loader.\n",
        "            if evaluators is not None:\n",
        "                evaluator = evaluators[idx]\n",
        "            else:\n",
        "                try:\n",
        "                    evaluator = cls.build_evaluator(cfg, dataset_name)\n",
        "                except NotImplementedError:\n",
        "                    logger.warn(\n",
        "                        \"No evaluator found. Use `DefaultTrainer.test(evaluators=)`, \"\n",
        "                        \"or implement its `build_evaluator` method.\"\n",
        "                    )\n",
        "                    results[dataset_name] = {}\n",
        "                    continue\n",
        "            results_i = inference_on_dataset(model, data_loader, evaluator)\n",
        "            results[dataset_name] = results_i\n",
        "            if comm.is_main_process():\n",
        "                assert isinstance(\n",
        "                    results_i, dict\n",
        "                ), \"Evaluator must return a dict on the main process. Got {} instead.\".format(\n",
        "                    results_i\n",
        "                )\n",
        "                logger.info(\"Evaluation results for {} in csv format:\".format(dataset_name))\n",
        "                print_csv_format(results_i)\n",
        "\n",
        "        if len(results) == 1:\n",
        "            results = list(results.values())[0]\n",
        "        return results\n",
        "\n",
        "    @staticmethod\n",
        "    def auto_scale_workers(cfg, num_workers: int):\n",
        "        \"\"\"\n",
        "        When the config is defined for certain number of workers (according to\n",
        "        ``cfg.SOLVER.REFERENCE_WORLD_SIZE``) that's different from the number of\n",
        "        workers currently in use, returns a new cfg where the total batch size\n",
        "        is scaled so that the per-GPU batch size stays the same as the\n",
        "        original ``IMS_PER_BATCH // REFERENCE_WORLD_SIZE``.\n",
        "\n",
        "        Other config options are also scaled accordingly:\n",
        "        * training steps and warmup steps are scaled inverse proportionally.\n",
        "        * learning rate are scaled proportionally, following :paper:`ImageNet in 1h`.\n",
        "\n",
        "        For example, with the original config like the following:\n",
        "\n",
        "        .. code-block:: yaml\n",
        "\n",
        "            IMS_PER_BATCH: 16\n",
        "            BASE_LR: 0.1\n",
        "            REFERENCE_WORLD_SIZE: 8\n",
        "            MAX_ITER: 5000\n",
        "            STEPS: (4000,)\n",
        "            CHECKPOINT_PERIOD: 1000\n",
        "\n",
        "        When this config is used on 16 GPUs instead of the reference number 8,\n",
        "        calling this method will return a new config with:\n",
        "\n",
        "        .. code-block:: yaml\n",
        "\n",
        "            IMS_PER_BATCH: 32\n",
        "            BASE_LR: 0.2\n",
        "            REFERENCE_WORLD_SIZE: 16\n",
        "            MAX_ITER: 2500\n",
        "            STEPS: (2000,)\n",
        "            CHECKPOINT_PERIOD: 500\n",
        "\n",
        "        Note that both the original config and this new config can be trained on 16 GPUs.\n",
        "        It's up to user whether to enable this feature (by setting ``REFERENCE_WORLD_SIZE``).\n",
        "\n",
        "        Returns:\n",
        "            CfgNode: a new config. Same as original if ``cfg.SOLVER.REFERENCE_WORLD_SIZE==0``.\n",
        "        \"\"\"\n",
        "        old_world_size = cfg.SOLVER.REFERENCE_WORLD_SIZE\n",
        "        if old_world_size == 0 or old_world_size == num_workers:\n",
        "            return cfg\n",
        "        cfg = cfg.clone()\n",
        "        frozen = cfg.is_frozen()\n",
        "        cfg.defrost()\n",
        "\n",
        "        assert (\n",
        "            cfg.SOLVER.IMS_PER_BATCH % old_world_size == 0\n",
        "        ), \"Invalid REFERENCE_WORLD_SIZE in config!\"\n",
        "        scale = num_workers / old_world_size\n",
        "        bs = cfg.SOLVER.IMS_PER_BATCH = int(round(cfg.SOLVER.IMS_PER_BATCH * scale))\n",
        "        lr = cfg.SOLVER.BASE_LR = cfg.SOLVER.BASE_LR * scale\n",
        "        max_iter = cfg.SOLVER.MAX_ITER = int(round(cfg.SOLVER.MAX_ITER / scale))\n",
        "        warmup_iter = cfg.SOLVER.WARMUP_ITERS = int(round(cfg.SOLVER.WARMUP_ITERS / scale))\n",
        "        cfg.SOLVER.STEPS = tuple(int(round(s / scale)) for s in cfg.SOLVER.STEPS)\n",
        "        cfg.TEST.EVAL_PERIOD = int(round(cfg.TEST.EVAL_PERIOD / scale))\n",
        "        cfg.SOLVER.CHECKPOINT_PERIOD = int(round(cfg.SOLVER.CHECKPOINT_PERIOD / scale))\n",
        "        cfg.SOLVER.REFERENCE_WORLD_SIZE = num_workers  # maintain invariant\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info(\n",
        "            f\"Auto-scaling the config to batch_size={bs}, learning_rate={lr}, \"\n",
        "            f\"max_iter={max_iter}, warmup={warmup_iter}.\"\n",
        "        )\n",
        "\n",
        "        if frozen:\n",
        "            cfg.freeze()\n",
        "        return cfg\n",
        "\n",
        "# Access basic attributes from the underlying trainer\n",
        "for _attr in [\"model\", \"data_loader\", \"optimizer\"]:\n",
        "    setattr(\n",
        "        CustomizeTrainer,\n",
        "        _attr,\n",
        "        property(\n",
        "            # getter\n",
        "            lambda self, x=_attr: getattr(self._trainer, x),\n",
        "            # setter\n",
        "            lambda self, value, x=_attr: setattr(self._trainer, x, value),\n",
        "        ),\n",
        "    )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67JkBKzEt3iG",
        "outputId": "f74ce15c-e4ea-472c-fd5f-76f62e0e9497"
      },
      "source": [
        "trainer = CustomizeTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "#trainer.train()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "456456456\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 2\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ()\n",
            "  TRAIN: ('balloon_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 50\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 128\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 1\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.00025\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 2\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 300\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: []\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0 ShapeSpec(channels=3, height=None, width=None, stride=None)\n",
            "stages\n",
            "123123123123123\n",
            "Model GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[12/02 09:28:43 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 61 images left.\n",
            "\u001b[32m[12/02 09:28:43 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|  balloon   | 255          |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[12/02 09:28:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[12/02 09:28:43 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[12/02 09:28:43 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/02 09:28:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.17 MiB\n",
            "+------------------------------------------------------+------------+\n",
            "|                       Modules                        | Parameters |\n",
            "+------------------------------------------------------+------------+\n",
            "|             backbone.fpn_lateral2.weight             |   65536    |\n",
            "|              backbone.fpn_lateral2.bias              |    256     |\n",
            "|             backbone.fpn_output2.weight              |   589824   |\n",
            "|              backbone.fpn_output2.bias               |    256     |\n",
            "|             backbone.fpn_lateral3.weight             |   131072   |\n",
            "|              backbone.fpn_lateral3.bias              |    256     |\n",
            "|             backbone.fpn_output3.weight              |   589824   |\n",
            "|              backbone.fpn_output3.bias               |    256     |\n",
            "|             backbone.fpn_lateral4.weight             |   262144   |\n",
            "|              backbone.fpn_lateral4.bias              |    256     |\n",
            "|             backbone.fpn_output4.weight              |   589824   |\n",
            "|              backbone.fpn_output4.bias               |    256     |\n",
            "|             backbone.fpn_lateral5.weight             |   524288   |\n",
            "|              backbone.fpn_lateral5.bias              |    256     |\n",
            "|             backbone.fpn_output5.weight              |   589824   |\n",
            "|              backbone.fpn_output5.bias               |    256     |\n",
            "|      backbone.bottom_up.res3.0.shortcut.weight       |   131072   |\n",
            "|        backbone.bottom_up.res3.0.conv1.weight        |   32768    |\n",
            "|        backbone.bottom_up.res3.0.conv2.weight        |   147456   |\n",
            "|        backbone.bottom_up.res3.0.conv3.weight        |   65536    |\n",
            "|        backbone.bottom_up.res3.1.conv1.weight        |   65536    |\n",
            "|        backbone.bottom_up.res3.1.conv2.weight        |   147456   |\n",
            "|        backbone.bottom_up.res3.1.conv3.weight        |   65536    |\n",
            "|        backbone.bottom_up.res3.2.conv1.weight        |   65536    |\n",
            "|        backbone.bottom_up.res3.2.conv2.weight        |   147456   |\n",
            "|        backbone.bottom_up.res3.2.conv3.weight        |   65536    |\n",
            "|        backbone.bottom_up.res3.3.conv1.weight        |   65536    |\n",
            "|        backbone.bottom_up.res3.3.conv2.weight        |   147456   |\n",
            "|        backbone.bottom_up.res3.3.conv3.weight        |   65536    |\n",
            "|      backbone.bottom_up.res4.0.shortcut.weight       |   524288   |\n",
            "|        backbone.bottom_up.res4.0.conv1.weight        |   131072   |\n",
            "|        backbone.bottom_up.res4.0.conv2.weight        |   589824   |\n",
            "|        backbone.bottom_up.res4.0.conv3.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.1.conv1.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.1.conv2.weight        |   589824   |\n",
            "|        backbone.bottom_up.res4.1.conv3.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.2.conv1.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.2.conv2.weight        |   589824   |\n",
            "|        backbone.bottom_up.res4.2.conv3.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.3.conv1.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.3.conv2.weight        |   589824   |\n",
            "|        backbone.bottom_up.res4.3.conv3.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.4.conv1.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.4.conv2.weight        |   589824   |\n",
            "|        backbone.bottom_up.res4.4.conv3.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.5.conv1.weight        |   262144   |\n",
            "|        backbone.bottom_up.res4.5.conv2.weight        |   589824   |\n",
            "|        backbone.bottom_up.res4.5.conv3.weight        |   262144   |\n",
            "|      backbone.bottom_up.res5.0.shortcut.weight       |  2097152   |\n",
            "|        backbone.bottom_up.res5.0.conv1.weight        |   524288   |\n",
            "|        backbone.bottom_up.res5.0.conv2.weight        |  2359296   |\n",
            "|        backbone.bottom_up.res5.0.conv3.weight        |  1048576   |\n",
            "|        backbone.bottom_up.res5.1.conv1.weight        |  1048576   |\n",
            "|        backbone.bottom_up.res5.1.conv2.weight        |  2359296   |\n",
            "|        backbone.bottom_up.res5.1.conv3.weight        |  1048576   |\n",
            "|        backbone.bottom_up.res5.2.conv1.weight        |  1048576   |\n",
            "|        backbone.bottom_up.res5.2.conv2.weight        |  2359296   |\n",
            "|        backbone.bottom_up.res5.2.conv3.weight        |  1048576   |\n",
            "|       proposal_generator.rpn_head.conv.weight        |   589824   |\n",
            "|        proposal_generator.rpn_head.conv.bias         |    256     |\n",
            "| proposal_generator.rpn_head.objectness_logits.weight |    768     |\n",
            "|  proposal_generator.rpn_head.objectness_logits.bias  |     3      |\n",
            "|   proposal_generator.rpn_head.anchor_deltas.weight   |    3072    |\n",
            "|    proposal_generator.rpn_head.anchor_deltas.bias    |     12     |\n",
            "|            roi_heads.box_head.fc1.weight             |  12845056  |\n",
            "|             roi_heads.box_head.fc1.bias              |    1024    |\n",
            "|            roi_heads.box_head.fc2.weight             |  1048576   |\n",
            "|             roi_heads.box_head.fc2.bias              |    1024    |\n",
            "|       roi_heads.box_predictor.cls_score.weight       |    2048    |\n",
            "|        roi_heads.box_predictor.cls_score.bias        |     2      |\n",
            "|       roi_heads.box_predictor.bbox_pred.weight       |    4096    |\n",
            "|        roi_heads.box_predictor.bbox_pred.bias        |     4      |\n",
            "|         roi_heads.mask_head.mask_fcn1.weight         |   589824   |\n",
            "|          roi_heads.mask_head.mask_fcn1.bias          |    256     |\n",
            "|         roi_heads.mask_head.mask_fcn2.weight         |   589824   |\n",
            "|          roi_heads.mask_head.mask_fcn2.bias          |    256     |\n",
            "|         roi_heads.mask_head.mask_fcn3.weight         |   589824   |\n",
            "|          roi_heads.mask_head.mask_fcn3.bias          |    256     |\n",
            "|         roi_heads.mask_head.mask_fcn4.weight         |   589824   |\n",
            "|          roi_heads.mask_head.mask_fcn4.bias          |    256     |\n",
            "|          roi_heads.mask_head.deconv.weight           |   262144   |\n",
            "|           roi_heads.mask_head.deconv.bias            |    256     |\n",
            "|         roi_heads.mask_head.predictor.weight         |    256     |\n",
            "|          roi_heads.mask_head.predictor.bias          |     1      |\n",
            "+------------------------------------------------------+------------+\n",
            "Total Trainable Params: 43695638\n",
            "Resnet Params: 23232512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_f10217.pkl: 178MB [00:07, 24.5MB/s]                           \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xABLAgW_XlAK"
      },
      "source": [
        "# 23 232 512\n",
        "# 43 695 638"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6odmaCXTJBF"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twtKdJzo01Ze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "cb767137-ed29-4fcd-9d9a-f180ff297b84"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[12/02 08:45:15 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[12/02 08:45:26 d2.engine.hooks]: \u001b[0mOverall training speed: 6 iterations in 0:00:07 (1.2964 s / it)\n",
            "\u001b[32m[12/02 08:45:26 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:07 (0:00:00 on hooks)\n",
            "\u001b[32m[12/02 08:45:26 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 8  total_loss: 2.096  loss_cls: 0.6264  loss_box_reg: 0.7117  loss_mask: 0.6843  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.008478  time: 1.2265  data_time: 0.0662  lr: 6.0775e-06  max_mem: 2544M\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-c3ec7ec97695>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             assert hasattr(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c3ec7ec97695>\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/meta_arch/rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_generator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m\"proposals\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/proposal_generator/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, gt_instances)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mgt_instances\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RPN requires gt_instances in training!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_and_sample_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m             losses = self.losses(\n\u001b[1;32m    473\u001b[0m                 \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_objectness_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_anchor_deltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/proposal_generator/rpn.py\u001b[0m in \u001b[0;36mlabel_and_sample_anchors\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mmatch_quality_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_if_cuda_oom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairwise_iou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_boxes_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mmatched_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_if_cuda_oom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_matcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_quality_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;31m# Matching is memory-expensive and may result in CPU tensors. But the result is small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mgt_labels_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_labels_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgt_boxes_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/utils/memory.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_ignore_torch_cuda_oom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Clear cache and retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/matcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, match_quality_matrix)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_match_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_quality_matrix\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# match_quality_matrix is M (gt) x N (predicted)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQNoCCSgTK01"
      },
      "source": [
        "# Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql-g9cEaPeph"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2YcXc79Pi2o"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_balloon_dicts(\"balloon/val\")\n",
        "for d in random.sample(dataset_dicts, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=balloon_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}